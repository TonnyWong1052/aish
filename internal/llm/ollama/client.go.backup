package ollama

import (
	"bytes"
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"net/http"
	"regexp"
	"strings"
	"text/template"
	"time"

	"github.com/TonnyWong1052/aish/internal/config"
	"github.com/TonnyWong1052/aish/internal/llm"
	"github.com/TonnyWong1052/aish/internal/prompt"
)

// Ollama API structures
type ChatMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

type ChatRequest struct {
	Model    string        `json:"model"`
	Messages []ChatMessage `json:"messages"`
	Stream   bool          `json:"stream"`
}

type ChatResponse struct {
	Model     string      `json:"model"`
	CreatedAt string      `json:"created_at"`
	Message   ChatMessage `json:"message"`
	Done      bool        `json:"done"`
}

type GenerateRequest struct {
	Model  string `json:"model"`
	Prompt string `json:"prompt"`
	Stream bool   `json:"stream"`
}

type GenerateResponse struct {
	Model     string `json:"model"`
	CreatedAt string `json:"created_at"`
	Response  string `json:"response"`
	Done      bool   `json:"done"`
}

type ListModelsResponse struct {
	Models []struct {
		Name       string `json:"name"`
		ModifiedAt string `json:"modified_at"`
		Size       int64  `json:"size"`
	} `json:"models"`
}

// OllamaProvider implements the llm.Provider interface for local Ollama.
type OllamaProvider struct {
	cfg    config.ProviderConfig
	pm     *prompt.Manager
	client *http.Client
}

// NewProvider creates a new OllamaProvider.
func NewProvider(cfg config.ProviderConfig, pm *prompt.Manager) (llm.Provider, error) {
	client := &http.Client{
		Timeout: 120 * time.Second, // Longer timeout for local models
	}

	return &OllamaProvider{
		cfg:    cfg,
		pm:     pm,
		client: client,
	}, nil
}

func init() {
	llm.RegisterProvider("ollama", NewProvider)
}

// GetSuggestion implements the llm.Provider interface.
func (p *OllamaProvider) GetSuggestion(ctx context.Context, capturedContext llm.CapturedContext, lang string) (*llm.Suggestion, error) {
	// Get the prompt template
	promptTemplate, err := p.pm.GetPrompt("get_suggestion", mapLanguage(lang))
	if err != nil {
		return nil, fmt.Errorf("failed to get prompt template: %w", err)
	}

	// Execute template with context data
	data := struct {
		Command  string
		Stdout   string
		Stderr   string
		ExitCode int
	}{
		Command:  capturedContext.Command,
		Stdout:   capturedContext.Stdout,
		Stderr:   capturedContext.Stderr,
		ExitCode: capturedContext.ExitCode,
	}

	var tpl bytes.Buffer
	t := template.Must(template.New("prompt").Parse(promptTemplate))
	if err := t.Execute(&tpl, data); err != nil {
		return nil, fmt.Errorf("failed to execute template: %w", err)
	}

	// Make API request
	response, err := p.chatAPI(ctx, tpl.String())
	if err != nil {
		return nil, fmt.Errorf("Ollama API request failed: %w", err)
	}

	// Prefer JSON output
	cleaned := stripCodeFences(response)
	var obj struct {
		Explanation      string `json:"explanation"`
		Command          string `json:"command"`
		CorrectedCommand string `json:"corrected_command"`
		CorrectedCamel   string `json:"correctedCommand"`
	}
	if err := json.Unmarshal([]byte(cleaned), &obj); err == nil {
		cmd := obj.Command
		if cmd == "" {
			cmd = obj.CorrectedCommand
		}
		if cmd == "" {
			cmd = obj.CorrectedCamel
		}
		if strings.TrimSpace(cmd) != "" && strings.TrimSpace(obj.Explanation) != "" {
			return &llm.Suggestion{Explanation: strings.TrimSpace(obj.Explanation), CorrectedCommand: strings.TrimSpace(cmd)}, nil
		}
	}

	// Fallback: heuristic parsing
	return p.parseSuggestionResponse(response)
}

// GetEnhancedSuggestion implements the llm.Provider interface with enhanced context.
func (p *OllamaProvider) GetEnhancedSuggestion(ctx context.Context, enhancedCtx llm.EnhancedCapturedContext, lang string) (*llm.Suggestion, error) {
	// Get the enhanced prompt template
	promptTemplate, err := p.pm.GetPrompt("get_enhanced_suggestion", mapLanguage(lang))
	if err != nil {
		// Fall back to regular suggestion if enhanced template doesn't exist
		return p.GetSuggestion(ctx, enhancedCtx.CapturedContext, lang)
	}

	// Create template functions
	funcMap := template.FuncMap{
		"add": func(a, b int) int {
			return a + b
		},
	}

	// Execute template with enhanced context data
	var tpl bytes.Buffer
	t, err := template.New("prompt").Funcs(funcMap).Parse(promptTemplate)
	if err != nil {
		return nil, fmt.Errorf("failed to parse enhanced template: %w", err)
	}

	if err := t.Execute(&tpl, enhancedCtx); err != nil {
		return nil, fmt.Errorf("failed to execute enhanced template: %w", err)
	}

	// Make API request
	response, err := p.chatAPI(ctx, tpl.String())
	if err != nil {
		return nil, fmt.Errorf("Ollama API request failed for enhanced suggestion: %w", err)
	}

	// Prefer JSON output (same parsing logic as regular GetSuggestion)
	cleaned := stripCodeFences(response)
	var obj struct {
		Explanation      string `json:"explanation"`
		Command          string `json:"command"`
		CorrectedCommand string `json:"corrected_command"`
		CorrectedCamel   string `json:"correctedCommand"`
	}
	if err := json.Unmarshal([]byte(cleaned), &obj); err == nil {
		cmd := obj.Command
		if cmd == "" {
			cmd = obj.CorrectedCommand
		}
		if cmd == "" {
			cmd = obj.CorrectedCamel
		}
		if strings.TrimSpace(cmd) != "" && strings.TrimSpace(obj.Explanation) != "" {
			return &llm.Suggestion{Explanation: strings.TrimSpace(obj.Explanation), CorrectedCommand: strings.TrimSpace(cmd)}, nil
		}
	}

	// Fallback: heuristic parsing
	return p.parseSuggestionResponse(response)
}

// GenerateCommand implements the llm.Provider interface.
func (p *OllamaProvider) GenerateCommand(ctx context.Context, promptText string, lang string) (string, error) {
	// Get the prompt template
	promptTemplate, err := p.pm.GetPrompt("generate_command", mapLanguage(lang))
	if err != nil {
		return "", fmt.Errorf("failed to get prompt template: %w", err)
	}

	// Execute template with prompt data
	data := struct{ Prompt string }{Prompt: promptText}
	var tpl bytes.Buffer
	t := template.Must(template.New("prompt").Parse(promptTemplate))
	if err := t.Execute(&tpl, data); err != nil {
		return "", fmt.Errorf("failed to execute template: %w", err)
	}

	// Make API request
	response, err := p.chatAPI(ctx, tpl.String())
	if err != nil {
		return "", fmt.Errorf("Ollama API request failed: %w", err)
	}

	// Prefer JSON output
	cleaned := stripCodeFences(response)
	var obj struct {
		Command string `json:"command"`
	}
	if err := json.Unmarshal([]byte(cleaned), &obj); err == nil && strings.TrimSpace(obj.Command) != "" {
		return strings.TrimSpace(obj.Command), nil
	}

	// Fallback: extract plausible shell command
	if cmd := extractPlausibleCommand(response); cmd != "" {
		return cmd, nil
	}
	return "", fmt.Errorf("no plausible command found in provider response")
}

// VerifyConnection implements the llm.Provider interface.
func (p *OllamaProvider) VerifyConnection(ctx context.Context) ([]string, error) {
	// Check if Ollama is running by listing models
	req, err := http.NewRequestWithContext(ctx, "GET", p.cfg.APIEndpoint+"/api/tags", nil)
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	resp, err := p.client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("Ollama is not running or not accessible at %s: %w", p.cfg.APIEndpoint, err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != 200 {
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("Ollama API returned status %d: %s", resp.StatusCode, string(body))
	}

	// Parse available models
	var listResp ListModelsResponse
	if err := json.NewDecoder(resp.Body).Decode(&listResp); err != nil {
		return nil, fmt.Errorf("failed to decode models list: %w", err)
	}

	if len(listResp.Models) == 0 {
		return nil, errors.New("no models available in Ollama. Please run 'ollama pull <model>' first")
	}

	// Return list of available models
	var models []string
	for _, model := range listResp.Models {
		models = append(models, model.Name)
	}

	return models, nil
}

// chatAPI makes a request to Ollama Chat API
func (p *OllamaProvider) chatAPI(ctx context.Context, message string) (string, error) {
	reqBody := ChatRequest{
		Model: p.cfg.Model,
		Messages: []ChatMessage{
			{Role: "user", Content: message},
		},
		Stream: false,
	}

	jsonBody, err := json.Marshal(reqBody)
	if err != nil {
		return "", fmt.Errorf("failed to marshal request: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, "POST", p.cfg.APIEndpoint+"/api/chat", bytes.NewReader(jsonBody))
	if err != nil {
		return "", fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")

	resp, err := p.client.Do(req)
	if err != nil {
		return "", fmt.Errorf("request failed: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != 200 {
		body, _ := io.ReadAll(resp.Body)
		return "", fmt.Errorf("API returned status %d: %s", resp.StatusCode, string(body))
	}

	// Parse response
	var chatResp ChatResponse
	if err := json.NewDecoder(resp.Body).Decode(&chatResp); err != nil {
		return "", fmt.Errorf("failed to decode response: %w", err)
	}

	return chatResp.Message.Content, nil
}

// parseSuggestionResponse parses the Ollama response to extract explanation and command
func (p *OllamaProvider) parseSuggestionResponse(response string) (*llm.Suggestion, error) {
	response = strings.TrimSpace(response)

	var explanation string
	var correctedCommand string

	lines := strings.Split(response, "\n")
	explanationFound := false
	commandFound := false

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}

		// Look for explanation markers
		if strings.Contains(strings.ToLower(line), "explanation") && !explanationFound {
			explanationFound = true
			if idx := strings.Index(strings.ToLower(line), "explanation"); idx != -1 {
				afterExplanation := strings.TrimSpace(line[idx+len("explanation"):])
				afterExplanation = strings.TrimLeft(afterExplanation, ":")
				afterExplanation = strings.TrimSpace(afterExplanation)
				if afterExplanation != "" {
					explanation = afterExplanation
				}
			}
			continue
		}

		// Look for command markers
		if (strings.Contains(strings.ToLower(line), "corrected") ||
			strings.Contains(strings.ToLower(line), "command")) && !commandFound {
			commandFound = true
			parts := strings.Split(line, ":")
			if len(parts) > 1 {
				cmd := strings.TrimSpace(parts[len(parts)-1])
				cmd = strings.Trim(cmd, "`")
				if cmd != "" && !strings.Contains(strings.ToLower(cmd), "command") {
					correctedCommand = cmd
				}
			}
			continue
		}

		if explanationFound && explanation == "" && !strings.Contains(strings.ToLower(line), "command") {
			explanation = line
			explanationFound = false
			continue
		}

		if commandFound && correctedCommand == "" {
			cmd := strings.Trim(line, "`")
			if cmd != "" {
				correctedCommand = cmd
			}
			commandFound = false
			continue
		}
	}

	// If we didn't find structured response, try to extract from the full response
	if explanation == "" || correctedCommand == "" {
		if strings.Contains(response, "Explanation:") && strings.Contains(response, "Corrected Command:") {
			parts := strings.Split(response, "Corrected Command:")
			if len(parts) >= 2 {
				correctedCommand = strings.TrimSpace(strings.Trim(parts[1], "`"))
				explanationPart := strings.Split(parts[0], "Explanation:")
				if len(explanationPart) >= 2 {
					explanation = strings.TrimSpace(explanationPart[1])
				}
			}
		} else {
			explanation = response
			if start := strings.Index(response, "`"); start != -1 {
				if end := strings.Index(response[start+1:], "`"); end != -1 {
					correctedCommand = response[start+1 : start+1+end]
				}
			}
		}
	}

	// Final fallbacks
	if explanation == "" {
		explanation = "Please check command syntax and parameters."
	}
	if correctedCommand == "" {
		correctedCommand = "echo 'Unable to auto-correct command, please check manually'"
	}

	return &llm.Suggestion{
		Explanation:      explanation,
		CorrectedCommand: correctedCommand,
	}, nil
}

// Helper functions

func mapLanguage(lang string) string {
	switch strings.ToLower(lang) {
	case "chinese", "zh", "zh-TW", "zh-CN":
		return "zh-TW"
	case "english", "en":
		return "en"
	default:
		return "en"
	}
}

func stripCodeFences(s string) string {
	s = strings.TrimSpace(s)
	if strings.HasPrefix(s, "```") {
		s = strings.TrimPrefix(s, "```")
		s = strings.TrimSpace(s)
		if strings.HasPrefix(strings.ToLower(s), "json") {
			s = strings.TrimSpace(s[4:])
		}
		if idx := strings.LastIndex(s, "```"); idx != -1 {
			s = s[:idx]
		}
	}
	return strings.TrimSpace(strings.Trim(s, "`"))
}

func extractPlausibleCommand(text string) string {
	s := strings.TrimSpace(text)
	if s == "" {
		return ""
	}
	// Reject obvious prose answers
	lower := strings.ToLower(s)
	banned := []string{"i am", "i'm", "i cannot", "i can't", "large language model", "sorry", "cannot answer", "i don't"}
	for _, b := range banned {
		if strings.Contains(lower, b) {
			return ""
		}
	}
	// Prefer fenced code blocks
	if i := strings.LastIndex(s, "```"); i != -1 {
		start := strings.LastIndex(s[:i], "```")
		if start != -1 && start < i {
			block := s[start+3 : i]
			for _, line := range strings.Split(block, "\n") {
				line = strings.TrimSpace(line)
				if line == "" || strings.HasPrefix(line, "#") {
					continue
				}
				if plausibleCommand(line) {
					return line
				}
			}
		}
	}
	// Scan lines
	for _, line := range strings.Split(s, "\n") {
		line = strings.TrimSpace(line)
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}
		if plausibleCommand(line) {
			return line
		}
	}
	return ""
}

var cmdStartRe = regexp.MustCompile(`^(?i)\s*(sudo\s+)?([a-z][a-z0-9._-]*|\.|\.\.|\./|/|~)(\s|$)`)

func plausibleCommand(line string) bool {
	l := strings.TrimSpace(line)
	if l == "" {
		return false
	}
	if strings.HasPrefix(l, "bash") {
		l = strings.TrimSpace(strings.TrimPrefix(l, "bash"))
		if l == "" {
			return false
		}
	}
	if !cmdStartRe.MatchString(l) {
		return false
	}
	if strings.HasSuffix(l, ".") && !strings.ContainsAny(l, "/-'_\"$&|><") {
		return false
	}
	return true
}
